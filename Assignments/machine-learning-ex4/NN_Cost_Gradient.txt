function  [J grad] = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y,lambda)

%We have 3 layer NN 

%Reshaping nn_params (column vector) as two matrixes 

Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)),hidden_layer_size, (input_layer_size + 1));

Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), num_labels, (hidden_layer_size + 1));

% Setup some useful variables
m = size(X, 1);
         
J = 0;
Theta1_grad = zeros(size(Theta1));
Theta2_grad = zeros(size(Theta2));


%Calculate the Cost function

X = [ones(m, 1) X];

a2 = sigmoid(Theta1*X.');  %sigmoid is an external function

a2 = [ones(1,m);a2];

hipothesis = sigmoid(Theta2*a2);

hipothesis = hipothesis.';

y_def = zeros(m,num_labels);

for i=1:m 
    y_def(i,y(i)) = 1;
end

Ji = 0;

for k =1:m
    for i = 1:num_labels
        Ji = -1*y_def(k,i)*log(hipothesis(k,i)) -1*(1-y_def(k,i))*log(1-hipothesis(k,i));
        J = J + Ji;
    end
end

J = J/m;


%Calculate the regularized cost function 

JTheta1=0;
JTheta2=0;

for k=1:size(Theta1,1)
    for i =2:size(Theta1,2)
       Ji = Theta1(k,i)^2;
       JTheta1 = JTheta1 + Ji;
    end
end

for k=1:size(Theta2,1)
    for i =2:size(Theta2,2)
       Ji = Theta2(k,i)^2;
       JTheta2 = JTheta2 + Ji;
    end
end

J = J + (lambda/(2*m))*(JTheta1+JTheta2);

%Calculate the matrixes with partial derivates. We have accumalated variables that increase for each instance during the backward phase

for i=1:m
  z_2 = X(i,:)*(Theta1.');
  a_2 = sigmoid(z_2);
  a_2 = [1,a_2];
  z_3 = a_2 *(Theta2.');
  a_3 = sigmoid(z_3);
  a_3 = a_3.';
  y_d = y_def(i,:);
  y_d = y_d.';
  d_3 = a_3 - y_d;
  d_2 = ((Theta2(:,2:end).')*d_3).*sigmoidGradient(z_2.');  %sigmoidGradient is an external function. Derivative of sigmoid in dz.
  Theta1_grad = Theta1_grad + d_2*X(i,:); %accumulated variable
  Theta2_grad = Theta2_grad + d_3*a_2; %accumulated variable
end

Theta1_grad = Theta1_grad/m;
Theta2_grad = Theta2_grad/m;


%From here I will calculate the regularized partial derivates matrixes. The code is wrong because the submit function doesn't assign me the score.

%Theta1_0 = Theta1;
%Theta1_0(:,1) = zeros(size(Theta1_0,1),1);
%Theta1_0*(lambda/m);

%Theta1_grad = Theta1_grad + Theta1_0;

%Theta2_0 = Theta2;
%Theta2_0(:,1) = zeros(size(Theta2_0,1),1);
%Theta2_0*(lambda/m);

%Theta2_grad = Theta2_grad + Theta2_0;
% -------------------------------------------------------------

% =========================================================================

% Unroll gradients
grad = [Theta1_grad(:) ; Theta2_grad(:)];


end
